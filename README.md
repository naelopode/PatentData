![](images/banner.png)

This repository contains the code used in my Master's thesis at EPFL, LHST Lab (2025).
The tools developed here are designed to process and analyze patent data, focusing on the extraction of information from patent documents from images with OCR and NLP, classification of patents using CPC classification, and clustering inventors/assignee...
# PatentData Repository Structure
```
ðŸ“¦ PatentData
â”œâ”€Â analysis
â”‚  â”œ rename.json 
â”‚  â”” template.json # How to use the data for analysis
â”œâ”€Â clustering
â”‚Â Â â””â”€Â clustering.py # Patentee clustering algorithm
â”œâ”€Â processing
â”‚Â Â â”œâ”€Â classification
â”‚Â Â â”‚Â Â â””â”€Â multiclass_pytorch.py # Use a multiclass multioutput classifier to classify patent titles in CPC Classifications
â”‚Â Â â”œâ”€Â extractio
â”‚Â Â â”‚Â Â â”œâ”€Â ID2Dates
â”‚Â Â â”‚Â Â â”‚Â Â â””â”€Â german_dates.ipynb # Validate hypothesis that you can predict publication dates based on patent ids.
â”‚Â Â â”‚Â Â â”œâ”€Â llm
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â compare_json.ipynb # Compare the results of different extraction methods
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â gemma.ipynb
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â google_api.ipynb
â”‚Â Â â”‚Â Â â”‚Â Â â”œâ”€Â LambdaLabda_api.ipynb
â”‚Â Â â”‚Â Â â”‚Â Â â””â”€Â OpenAI_api.ipynb
â”‚Â Â â”‚Â Â â””â”€Â spacy
â”‚Â Â â”‚Â Â Â Â Â â”œâ”€Â run_spacy.py # Execute extraction on OCR
â”‚Â Â â”‚Â Â Â Â Â â”œâ”€Â spacy_de.ipynb # Train german spacy model
â”‚Â Â â”‚Â Â Â Â Â â”œâ”€Â spacy_fr.ipynb # Train french spacy model
â”‚Â Â â”‚Â Â Â Â Â â”œâ”€Â spacy_gb.ipynb # Train british spacy model
â”‚Â Â â”‚Â Â Â Â Â â””â”€Â spacy.ipyb # Train american spacy model
â”‚  â”œâ”€Â ocr
â”‚  â”‚Â Â â”œâ”€Â page_labels # This part is for predicting patent page type
â”‚  â”‚Â Â â”‚Â Â â”œâ”€Â create_dataloader.py
â”‚  â”‚Â Â â”‚Â Â â”œâ”€Â create_model.py
â”‚  â”‚Â Â â”‚Â Â â””â”€Â preditct_type.py
â”‚  â”‚Â Â â”œâ”€Â parellel_start.py
â”‚  â”‚Â Â â””â”€Â tesseract_pipeline.py
â”‚  â”œâ”€Â scraper 
â”‚  â”‚Â Â â”œâ”€Â fetch_pdf_us.ipynb
â”‚  â”‚Â Â â””â”€Â google_patents_scrape.py
â”‚  â””â”€Â upload
â”‚   Â Â â”œâ”€Â aggregate.py
â”‚   Â Â â”œâ”€Â classification_predictor.py
â”‚   Â Â â”œâ”€Â import_json.py # Upload json patent metadata to the database
â”‚   Â Â â”œâ”€Â import_txt.py # Upload txt patent metdata to the database
â”‚   Â Â â”œâ”€Â schema.csv # Schema from json and txt to database
â”‚   Â Â â””â”€Â upload_text.py # Upload already OCRized text to the database
â”œâ”€ images
â”‚  â””â”€ banner.png
â”œâ”€Â README.md
â”œâ”€Â thesis.pdf
â””â”€ requirements.txt
```
# Installation
To run the code in this repository, you need to install the required packages. You can do this by running the following command in your terminal:
```bash
pip install -r requirements.txt
```
The dataset is contained in MongoDB, you can run one in a docker container:
```bash
docker run --name mongodb -d -p 27017:27017 mongo
```

You then need to import the dataset into MongoDB. To load the .dump file, you can use the following command:
```bash
mongorestore --db patentdata --drop /path/to/patentdata.dump
```

The dataset is available in the `patentdata.dump` file, which can be found on [Kaggle](https://www.kaggle.com/datasets/naelopode/patentdata)

