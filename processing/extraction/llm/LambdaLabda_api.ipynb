{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e4fe3e9",
   "metadata": {},
   "source": [
    "This is used for benchmark purposes, not a optimized pipeline for llm extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "import datetime\n",
    "class Patent(BaseModel):\n",
    "    title : str\n",
    "    Application_Date: Optional[datetime.date]\n",
    "    Publication_Date: Optional[datetime.date] \n",
    "    Applicants: list[str]\n",
    "    Inventors: list[str]\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "# serialize pydantic model into json schema\n",
    "pydantic_schema = Patent.schema_json()\n",
    "openai_api_key = 'API_KEY'\n",
    "prompt = f\"You are a helpful assistant that transform historical scans of patents to a JSON format. Make sure to get the dates and names correct. Take a second to think about your answer. Only output a json data, no explanation. Here's the json schema you must adhere to:\\n{pydantic_schema}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymongo import UpdateOne\n",
    "from tqdm import tqdm\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "client = MongoClient(\"localhost\", 29012)\n",
    "db = client[\"test-database\"]\n",
    "collection_json = db[\"collection-json\"]\n",
    "def generate_query(item):\n",
    "    text_clean = item['OCR'].decode('utf-8').replace('\\n\\n', ' ')\n",
    "    return text_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ef21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "count_token = 0\n",
    "model = 'Llama-4-scout-17b-16e-instruct'\n",
    "os.mkdir(f\"/scratch/students/ndillenb/metadata/processing/llm/json_compare/{model}_json_compare/\") if not os.path.exists(f\"/scratch/students/ndillenb/metadata/processing/llm/json_compare/{model}_json_compare/\") else None\n",
    "for item in tqdm(list(collection_json.find({'Country':\"US\", 'OCR': {'$exists': True}, 'Title': {'$exists': True}, 'C_Application Date': {'$exists': True}, 'C_Publication Date': {'$exists': True}, 'clean_applicants': {'$exists': True}, 'clean_inventor': {'$exists': True}}).limit(100))):\n",
    "    query = generate_query(item)\n",
    "    openai_api_base = \"https://api.lambda.ai/v1\"\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=openai_api_key,\n",
    "        base_url=openai_api_base,\n",
    "    )\n",
    "\n",
    "    count_token += len(f\"{prompt}\\n The patent text is: {query}\\n\\n\")/4\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "    messages=[{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": prompt\n",
    "    }, {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"The patent text is: {query}\"\n",
    "    }],\n",
    "    model=model,\n",
    "    )\n",
    "    print('--response is--')\n",
    "    print(chat_completion)\n",
    "    json_llm = ''\n",
    "    if \"```json\\n\" in chat_completion.choices[0].message.content:\n",
    "        try:\n",
    "            response = chat_completion.choices[0].message.content[chat_completion.choices[0].message.content.find('```json\\n'):chat_completion.choices[0].message.content.find('}```')]\n",
    "            json_llm = response.strip('```json\\n').strip('```')\n",
    "            # Parse the JSON content into a Python dictionary\n",
    "            json_llm = json.loads(json_llm)\n",
    "        except:\n",
    "            print('error parsing json')\n",
    "            print(response)\n",
    "            json_llm = None\n",
    "    elif chat_completion.choices[0].message.content.startswith('{') or chat_completion.choices[0].message.content.replace('\\n', '').replace(\"```\", \"\").startswith('{'):\n",
    "        response = chat_completion.choices[0].message.content\n",
    "        try:\n",
    "            json_llm = response.replace('\\n', '').replace(\"```\", \"\")\n",
    "            # Parse the JSON content into a Python dictionary\n",
    "            json_llm = json.loads(json_llm)\n",
    "        except:\n",
    "            print('error parsing json')\n",
    "            print(response)\n",
    "            json_llm = None\n",
    "    # Store results for later evaluation\n",
    "    with open(f\"/scratch/students/ndillenb/metadata/processing/llm/json_compare/{model}_json_compare/json_llm_{item['_id']}.json\", \"w\") as f:\n",
    "        data = {'Title': item['Title'], 'Application_Date': item['C_Application Date'], 'Publication_Date': item['C_Publication Date'], 'Applicants': item['clean_applicants'], 'Inventors': item['clean_inventor']}\n",
    "        # Convert datetime objects to strings for JSON serialization\n",
    "        data_serializable = {\n",
    "            key: (value.isoformat() if isinstance(value, datetime) else value)\n",
    "            for key, value in data.items()\n",
    "        }\n",
    "        json.dump({'predicted': json_llm, 'expected': data_serializable}, f)\n",
    "    print(f\"Currently at about {count_token} tokens\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metadata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
