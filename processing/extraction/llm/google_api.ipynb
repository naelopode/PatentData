{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c41283f5",
   "metadata": {},
   "source": [
    "This is used for benchmark purposes, not a optimized pipeline for llm extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "import datetime\n",
    "class Patent(BaseModel):\n",
    "    title : str\n",
    "    Application_Date: Optional[datetime.datetime]\n",
    "    Publication_Date: Optional[datetime.datetime]\n",
    "    Applicants: list[str]\n",
    "    Inventors: list[str]\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"additionalProperties\": False,\n",
    "            \"json_encoders\": {\n",
    "                datetime.datetime: lambda v: v.isoformat()\n",
    "            }\n",
    "        }\n",
    "# serialize pydantic model into json schema\n",
    "pydantic_schema = Patent.schema_json()\n",
    "\n",
    "prompt = f\"You are a helpful assistant that transform historical scans of patents to a JSON format. Make sure to get the dates and names correct and only include keys 'title', 'Application_Date', 'Publication_Date', 'Applicants', 'Inventors'. Take a second to think about your answer. Here's the json schema you must adhere to:\\n{pydantic_schema}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymongo import UpdateOne\n",
    "from tqdm import tqdm\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "client = MongoClient(\"localhost\", 29012)\n",
    "db = client[\"test-database\"]\n",
    "collection_json = db[\"collection-json\"]\n",
    "def generate_query(item):\n",
    "    text_clean = item['OCR'].decode('utf-8').replace('\\n\\n', ' ')\n",
    "    return text_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ef21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import json\n",
    "import os\n",
    "count_token = 0\n",
    "model = 'gemini-1.5-flash'\n",
    "os.mkdir(f\"/scratch/students/ndillenb/metadata/processing/llm/json_compare/{model.replace('/','-')}_json_compare\") if not os.path.exists(f\"/scratch/students/ndillenb/metadata/processing/llm/json_compare/{model.replace('/','-')}_json_compare\") else None\n",
    "for item in tqdm(list(collection_json.find({'Country':\"US\", 'OCR': {'$exists': True}, 'Title': {'$exists': True}, 'C_Application Date': {'$exists': True}, 'C_Publication Date': {'$exists': True}, 'clean_applicants': {'$exists': True}, 'clean_inventor': {'$exists': True}}).limit(100))):\n",
    "    query = generate_query(item)\n",
    "    #print(query)\n",
    "    client = genai.Client(api_key=\"API_KEY\")\n",
    "    count_token += len(f\"{prompt}\\n The patent text is: {query}\\n\\n\")/4\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=f\"{prompt}. The latent text is: {query}\",\n",
    "        config=types.GenerateContentConfig(\n",
    "            safety_settings=[\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                ),\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory. HARM_CATEGORY_HATE_SPEECH,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                ),\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                ),\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory. HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                ),\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory. HARM_CATEGORY_CIVIC_INTEGRITY,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                )],\n",
    "        )\n",
    "    )\n",
    "    print('--response is--')\n",
    "    print(response)\n",
    "    json_llm = ''\n",
    "    if '```json' in response.text:\n",
    "        try:\n",
    "            json_llm = response.text.strip('```json\\n').strip('```').strip('\\n')\n",
    "            json_llm = json_llm[json_llm.index('{'):]\n",
    "            # Parse the JSON content into a Python dictionary\n",
    "            json_llm = json.loads(json_llm)\n",
    "        except:\n",
    "            print('error parsing json but started with json')\n",
    "            print(json_llm)\n",
    "            json_llm = None\n",
    "    elif response.text.startswith('{'):\n",
    "        try:\n",
    "            json_llm = response.text.replace(\"'\", '\"').strip('\\n')\n",
    "            # Parse the JSON content into a Python dictionary\n",
    "            json_llm = json.loads(json_llm)\n",
    "            if 'properties' in json_llm:\n",
    "                json_llm = json_llm['properties']\n",
    "        except:\n",
    "            print('error parsing json but started with {')\n",
    "            print(json_llm)\n",
    "            json_llm = None\n",
    "    else:\n",
    "        print(f\"Error parsing JSON: {response.text} \")\n",
    "    # Store in json file for later evaluation\n",
    "    with open(f\"/scratch/students/ndillenb/metadata/processing/llm/json_compare/{model.replace('/','-')}_json_compare/json_llm_{item['_id']}.json\", \"w\") as f:\n",
    "        data = {'Title': item['Title'], 'Application_Date': item['C_Application Date'], 'Publication_Date': item['C_Publication Date'], 'Applicants': item['clean_applicants'], 'Inventors': item['clean_inventor']}\n",
    "        # Convert datetime objects to strings for JSON serialization\n",
    "        data_serializable = {\n",
    "            key: (value.isoformat() if isinstance(value, datetime) else value)\n",
    "            for key, value in data.items()\n",
    "        }\n",
    "        json.dump({'predicted': json_llm, 'expected': data_serializable}, f)\n",
    "    print(f\"Currently at about {count_token} tokens\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5337289d",
   "metadata": {},
   "source": [
    "# With pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5683a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "def generate_images(filename):\n",
    "    # Convert PDF to a list of PIL images\n",
    "    filename = os.path.join('/scratch/students/ndillenb/metadata/processing/llm/us_sample_patents', filename+'.pdf')\n",
    "    images = convert_from_path(filename)\n",
    "    return images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cde61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import json\n",
    "import os\n",
    "count_token = 0\n",
    "model = 'gemini-2.0-flash-lite'\n",
    "prefix = 'img_'\n",
    "os.mkdir(f\"/scratch/students/ndillenb/metadata/processing/llm/json_compare/{prefix}{model.replace('/','-')}_json_compare\") if not os.path.exists(f\"/scratch/students/ndillenb/metadata/processing/llm/json_compare/{prefix}{model.replace('/','-')}_json_compare\") else None\n",
    "for item in tqdm(list(collection_json.find({'Country':\"US\", 'OCR': {'$exists': True}, 'Title': {'$exists': True}, 'C_Application Date': {'$exists': True}, 'C_Publication Date': {'$exists': True}, 'clean_applicants': {'$exists': True}, 'clean_inventor': {'$exists': True}}).limit(100))[16:]):\n",
    "    print(f\"Trying to process {item['Country']}{item['Publication Number']}{item['Doc_kind']}\")\n",
    "    images = generate_images(f\"{item['Country']}{item['Publication Number']}{item['Doc_kind']}\")\n",
    "    print(f\"Transformed images\")\n",
    "    client = genai.Client(api_key=\"API_KEY\")\n",
    "    count_token += len(f\"{prompt}\\n\")/3. #Keep count of token for exepenses\n",
    "    for image in images:\n",
    "        largest_dimension = max(image.size)\n",
    "        count_token += int(largest_dimension/768 * 258) \n",
    "    query = [prompt]+[images]\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=query,\n",
    "        config=types.GenerateContentConfig(\n",
    "            safety_settings=[\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                ),\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory. HARM_CATEGORY_HATE_SPEECH,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                ),\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                ),\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory. HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                ),\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory. HARM_CATEGORY_CIVIC_INTEGRITY,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                )],\n",
    "        )\n",
    "    )\n",
    "    print('--response is--')\n",
    "    print(response)\n",
    "    json_llm = ''\n",
    "    if '```json' in response.text:\n",
    "        try:\n",
    "            json_llm = response.text.strip('```json\\n').strip('```').strip('\\n')\n",
    "            json_llm = json_llm[json_llm.index('{'):]\n",
    "            # Parse the JSON content into a Python dictionary\n",
    "            json_llm = json.loads(json_llm)\n",
    "        except:\n",
    "            print('error parsing json but started with json')\n",
    "            print(json_llm)\n",
    "            json_llm = None\n",
    "    elif response.text.startswith('{'):\n",
    "        try:\n",
    "            json_llm = response.text.replace(\"'\", '\"').strip('\\n')\n",
    "            # Parse the JSON content into a Python dictionary\n",
    "            json_llm = json.loads(json_llm)\n",
    "            if 'properties' in json_llm:\n",
    "                json_llm = json_llm['properties']\n",
    "        except:\n",
    "            print('error parsing json but started with {')\n",
    "            print(json_llm)\n",
    "            json_llm = None\n",
    "    else:\n",
    "        print(f\"Error parsing JSON: {response.text}\")\n",
    "    # Store in json file for later evaluation\n",
    "    with open(f\"/scratch/students/ndillenb/metadata/processing/llm/json_compare/{prefix}{model.replace('/','-')}_json_compare/json_llm_{item['_id']}.json\", \"w\") as f:\n",
    "        data = {'Title': item['Title'], 'Application_Date': item['C_Application Date'], 'Publication_Date': item['C_Publication Date'], 'Applicants': item['clean_applicants'], 'Inventors': item['clean_inventor']}\n",
    "        # Convert datetime objects to strings for JSON serialization\n",
    "        data_serializable = {\n",
    "            key: (value.isoformat() if isinstance(value, datetime) else value)\n",
    "            for key, value in data.items()\n",
    "        }\n",
    "        json.dump({'predicted': json_llm, 'expected': data_serializable}, f)\n",
    "    print(f\"Currently at about {count_token} tokens\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metadata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
